{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the library\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O\n",
    "import matplotlib.pyplot as plt # plotting library\n",
    "from IPython.display import display # Manage multiple output per cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Manage UTF-8 issue\n",
    "import sys  \n",
    "reload(sys)  \n",
    "sys.setdefaultencoding('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeVictory</th>\n",
       "      <th>HomeDefeat</th>\n",
       "      <th>HomeDraw</th>\n",
       "      <th>HomeGoal</th>\n",
       "      <th>ExtVictory</th>\n",
       "      <th>ExtDefeat</th>\n",
       "      <th>ExtDraw</th>\n",
       "      <th>ExtGoal</th>\n",
       "      <th>BetA</th>\n",
       "      <th>TrueResult_A</th>\n",
       "      <th>win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    HomeVictory  HomeDefeat  HomeDraw  HomeGoal  ExtVictory  ExtDefeat  \\\n",
       "2      0.666667    0.000000  0.333333  2.333333    0.000000   0.666667   \n",
       "7      0.000000    0.000000  1.000000  1.000000    0.333333   0.333333   \n",
       "8      1.000000    0.000000  0.000000  3.333333    0.333333   0.000000   \n",
       "11     0.000000    0.333333  0.666667  1.333333    0.333333   0.666667   \n",
       "12     0.333333    0.333333  0.333333  2.333333    0.000000   0.666667   \n",
       "\n",
       "     ExtDraw   ExtGoal  BetA  TrueResult_A  win  \n",
       "2   0.333333  1.666667   2.9             1  1.9  \n",
       "7   0.333333  3.000000   2.6             1  1.6  \n",
       "8   0.666667  1.666667   3.4             0  0.0  \n",
       "11  0.000000  1.000000   3.0             1  2.0  \n",
       "12  0.333333  1.000000   2.9             1  1.9  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing and cleaning the dataset\n",
    "df = pd.read_csv(\"../../data/result/D1-data-model-bet2.csv\")\n",
    "# hot-encoding\n",
    "df = pd.get_dummies(df)\n",
    "# remove useless column\n",
    "df.drop(df.columns[[8, 9, 10, 13, 14]], axis=1, inplace=True)\n",
    "# Create a win column containing the gain if bet was good\n",
    "df['win'] = df['BetA']-1\n",
    "df.loc[df.TrueResult_A == 0, 'win'] = 0\n",
    "# Removing column where bet is too high\n",
    "df = df.drop(df[df.BetA < 2].index)\n",
    "df = df.drop(df[df.BetA > 4].index)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get the X and y\n",
    "X = df[df.columns.drop(['BetA', 'TrueResult_A', 'win'])]\n",
    "y = df['TrueResult_A'].astype('bool_')\n",
    "win = df['win']\n",
    "# display(X, y, win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    178\n",
       "True      83\n",
       "Name: TrueResult_A, dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    79\n",
       "True     33\n",
       "Name: TrueResult_A, dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc_X = StandardScaler()\n",
    "# X_train = sc_X.fit_transform(X_train)\n",
    "# X_test = sc_X.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f1_score:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.18697729988052569"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.13101245052509006"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "f1_score = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=4, n_jobs=-1, scoring='f1')\n",
    "display('f1_score:',f1_score.mean(), f1_score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f1_score:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.18697729988052569"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.13101245052509006"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic = LogisticRegression()\n",
    "f1_score = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=4, n_jobs=-1, scoring='f1')\n",
    "display('f1_score:',f1_score.mean(), f1_score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid=[{'n_estimators': [3, 10, 30, 100, 300, 1000], 'max_features': ['sqrt', 'log2', None], 'criterion': ['gini', 'entropy']}, {'n_estimators': [3, 10, 30, 100, 300, 1000], 'max_features': [3, 5, 7], 'criterion': ['gini', 'entropy']}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying Grid Search to find the best hyper-parameters for our Logistic Regression Model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics.classification import log_loss\n",
    "from sklearn.metrics import make_scorer\n",
    "parameters = [{'n_estimators': [3, 10, 30, 100, 300, 1000], \n",
    "                'criterion': ['gini', 'entropy'], \n",
    "                'max_features': ['sqrt', 'log2', None]\n",
    "               },\n",
    "              {'n_estimators': [3, 10, 30, 100, 300, 1000], \n",
    "                'criterion': ['gini', 'entropy'], \n",
    "                'max_features': [3,5,7]\n",
    "               }]\n",
    "clf = GridSearchCV(estimator=classifier,\n",
    "                   param_grid=parameters,\n",
    "                   scoring='f1',\n",
    "                   cv=4,\n",
    "                   n_jobs=-1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40035518675685106"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract best score calculated with the GridSearchCV\n",
    "best_score = clf.best_score_\n",
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 3}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract best hyper-parameter calculated with the GridSearchCV\n",
    "best_params = clf.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'precision_score:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.49562198067632851"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.068430658025602734"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'recall_score:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.4433333333333333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.017118865486811765"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'f1_score:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.46589456539666829"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.030751637305352034"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluating scoring parameters\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Accuracy\n",
    "#accuracy_score = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=4, n_jobs=-1, scoring='accuracy')\n",
    "#display('accuracy_score:',accuracy_score.mean(), accuracy_score.std())\n",
    "# precision\n",
    "precision_score = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=4, n_jobs=-1, scoring='precision')\n",
    "display('precision_score:',precision_score.mean(), precision_score.std())\n",
    "# recall\n",
    "recall_score = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=4, n_jobs=-1, scoring='recall')\n",
    "display('recall_score:',recall_score.mean(), recall_score.std())\n",
    "# f1\n",
    "f1_score = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=4, n_jobs=-1, scoring='f1')\n",
    "display('f1_score:',f1_score.mean(), f1_score.std())\n",
    "# Cross entropy\n",
    "#from sklearn.metrics.classification import log_loss\n",
    "#log_loss_score = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=4, n_jobs=-1, scoring=make_scorer(log_loss, greater_is_better=False))\n",
    "#display('log_loss_score:',log_loss_score.mean(), log_loss_score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=3, n_jobs=1, oob_score=False, random_state=0,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training a new classifier using the best hyper-parameters\n",
    "clf = RandomForestClassifier(n_estimators=best_params['n_estimators'], \n",
    "                             criterion=best_params['criterion'], \n",
    "                             max_features=best_params['max_features'], \n",
    "                             random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, False, False, False, False,  True, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False,  True, False, False,  True,  True,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False,  True, False,  True, False, False,  True,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False,  True, False, False, False, False, False,  True, False,\n",
       "       False, False,  True, False,  True, False, False, False, False,\n",
       "       False, False,  True,  True,  True, False,  True, False, False,\n",
       "        True, False, False,  True, False, False, False,  True, False,\n",
       "       False, False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set result\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.        ],\n",
       "       [ 0.33333333,  0.66666667],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.33333333,  0.66666667],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.33333333,  0.66666667],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.33333333,  0.66666667],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 0.33333333,  0.66666667],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.44444444,  0.55555556],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.33333333,  0.66666667],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.33333333,  0.66666667],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.33333333,  0.66666667],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.33333333,  0.66666667],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.33333333,  0.66666667],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.33333333,  0.66666667],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 0.77777778,  0.22222222],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.33333333,  0.66666667],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 0.33333333,  0.66666667],\n",
       "       [ 0.5       ,  0.5       ],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.33333333,  0.66666667],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.33333333,  0.66666667],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 1.        ,  0.        ]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate target classification probability (got % instead of 1 or 0)\n",
    "y_probs = clf.predict_proba(X_test)\n",
    "y_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>62</td>\n",
       "      <td>17</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>88</td>\n",
       "      <td>24</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  False  True  All\n",
       "Actual                     \n",
       "False         62    17   79\n",
       "True          26     7   33\n",
       "All           88    24  112"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the confusion Matrix\n",
    "df_confusion = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.29166666666666669, 0.21212121212121213, 0.24561403508771931, None)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(y_test, y_pred, average='binary') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d836950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot of a ROC curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test.ravel(), y_probs[:, 1].ravel())\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "plt.title('ROC')\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b',\n",
    "label='AUC = %0.2f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.2])\n",
    "plt.ylim([-0.1,1.2])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check Important Feature\n",
    "list(zip(df.columns.drop('isSelling'), clf.feature_importances_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
